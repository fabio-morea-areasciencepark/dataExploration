--- 
title: "Exploration of company information"
author: "Fabio Morea"
date: "`r Sys.Date()`"

documentclass: scrbook
output:
  bookdown::pdf_book:
    template: null

site: bookdown::bookdown_site 

bibliography: book.bib
biblio-style: apalike
link-citations: yes
delete_merged_file: true
---
<!-- more options for pdf format -->
<!-- documentclass: scrbook -->
<!-- output: -->
<!--   bookdown::pdf_book: -->
<!--     template: null -->
 
<!-- documentclass: book -->
<!-- output: -->
<!--   bookdown::pdf_document2: default -->
<!--   bookdown::gitbook: default -->
<!-- site: bookdown::bookdown_site -->

 <!-- output: -->
 <!--  bookdown::pdf_book: -->
 <!--    base_format: rticles::jss_article -->
    
# Scope and objectives  

This notebook explores the datasets that will presumably underpin future research work for the PhD in Applied Data Science and Artificial Intelligence. 

## Background information: 
Research, innovation and highly skilled people are considered to be important factors in economic and social development. 
Economic support policies often include funds to support research (for example with the creation of public research infrastructures), companies (for example with tenders to co-finance innovative projects) and the training of people with the necessary skills.

Area Science Park is a national research institution that manages a science and technology park located in Trieste (Italy). Its activities can be considered a public investment in support of research and innovation, for a value of approximately 20 million euros per year. 

Currently Area is hosting 70 tenants (60 companies and 10 research centers) engaged in research activities in the fields of ICT, lifesceinces and materials. Their success (or lack of it) depends on a key - and often overlooked - asset: the community of over 1600 employees, researchers and entrepreneurs.  

Area is interested in measuring the effectiveness and efficiency of its activities, focusing in particular on 

- monitoring the economic performance of tenants,
- monitoring the community of skilled workers,
- comparing with similar groups, mainly at a regional or national scale, but also with respect to the science and technology parks in Austria and Slovenia.

To support research work, Area Science Park can provide some relevant datasets, cureated as a part of the project [*innovation intelligence*](https://www.innovationintelligence.it/). Innovation Intelligence aims to analyze information on companies in the Friuli Venezia Giulia region, using several data sources such as the chamber of commerce, the Regional Labor Market Observatory, a rating agency, as well as surveys on samples of companies. 

## Objectives of future research work - reserch questions
Research questions are currently defined on a general level: 

- are tenant companies performing better than similar companies?
- how to measure similarity between two companies?
- how to exthed such measure to groups of companies?
- how to identify clusters or communities of companies? 

The research questions above and the methodology outlined in this notebook are relevant also in other contexts, such ad sectoral cluster, public agencies supporting innovation and any kind of industrial area. The data set supports analysis focused on Friuli Venezia Giulia region, but can be extended to other regions (gathering relevant data from the Chamber of Commerce or from commercial data providers).

## About this notebook 
The notebook is divided in 6 sections: an introduction, a section for each dataset and a final section on potential future development.

1. Imprese_FVG
2. Bilanci_FVG
3. Rating_FVG 
4. CO_FVG
5. Features: A basic example of sample feature selection, on a small subset, where each company is represented by 5 features 
6. Further development: calculating the age of companies based on several dates, handling non metric features: defining a custimized similarity function to identify *similar* companies and estimate distances in a multi-dimensional space.


The notebook has been  written using *R-Studio* and rendered with *boowdown* (https://bookdown.org/) package. 
Data data manipulation is based on *tidyverse* [https://www.tidyverse.org/], a data science library that includes *magrittr* (pipe operator %>%), *dplyr* (select, summarize...), *tibble* (a tidier version of the data.frame) and *ggplot2* (visualizations).
A useful guide to tidverse is available online at the following address: [https://r4ds.had.co.nz/]

> TODO Some parts of the notebook are higlighted as "To Do", to highlight potential improvements in analysis, code efficiency or need for further clarifications.

## Data management plan

**Raw data:** The original data has been pre-pocessed by Area Science Park to fulfill the folloqing rquirements:

- encoded in UTF-8 cleaned from non-printable characters
- table columns are attributes (features, independent variables), renamed to be human- and machine-readable
- table rows are observations  If you have multiple tables, they should include a column in the table that allows them to be linked
- splitted into several tables, created unique identifiers to connect the tables
- saved each table to separate .csv file with a hunam-readable name
At this stage no attributes were removed or summarized. Raw data is available in local folder *data/raw*

**Tidy data:** This notebook explores all the attributes available in the raw data, and by merging, subsetting and transforming,  produces a smaller, cleaner data set ready for further analysis. Tidy data is saved in local folder *data/tidy*

This notebook describes the process to create tidy data, and the meaning of each variable:
- meaning, summary and visualizations ofeach attribute in tidy data
- information about attributes that are not contained in the tidy data (basic meaning and reason why thy have not been included)

**Updates:** raw and tidy data may be updated periodically, since Area Science Park updates the raw data set twice a year; anyway the current version in based on June 2021 version and does not provide automatic updating scripts. 


<!--chapter:end:index.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# Exploring dataset "companiesFVG" 
 

```{r include=FALSE}
# Local path, no need to display in knitted version
pathRawData = './../../_data/raw/imprese'
pathTidyData = './../../_data/tidy/'
library(tidyverse)
library(ggpubr)
library(ggthemes)
theme_set(theme_economist()) #theme_minimal()
```
 
This section is deditated to the exploration of data on companies that have a localization in Friuli Venezia Giulia. The origin of data is the Italian Business registry  (https://www.registroimprese.it/il-registro-imprese-per-la-p.a. ), and is managed by Infocamere (https://www.infocamere.it/). 

```{r}
data.files <- list.files(pathRawData, pattern = ".csv$", recursive = TRUE)
```
Pre-processed is availavle in folder **/data/raw**, organized in `r length(data.files)` files (namely `r data.files`). Each will be loaded in a different _data.frame_ and, after feature selection, saved in a new folder **/data/tidy**. 

## companies
The core data identifying companies can be found in *t_imprese.csv* . 
```{r}
companies <- read_delim( paste0(pathRawData,"/t_imprese.csv")) 
spec(companies) # tydiverse for str(companies)
```
The attributes belong to different groups: 

- *metadata*:ï..fonte, mm_aaaa: 
- *identifier*: id_impresa,reg_imp_n, cf, piva, denominazione 
- *address*:prov,sede_ul,n.albo_art,reg_imp_sez  
- *type of company*: ng2
- *active status*: stato_impresa  
- *dates*:data_ini_at, data_cess_att, data_fall, data_liquid, data_cost, data_isc_ri, data_isc_rd,data_isc_aa,data_canc
- *employees*:  addetti_aaaa, addetti_indip, addetti_dip  
- *share capital*: capitale, capitale_valuta 
- *other attributes*: imp_startup, imp_femminile, imp_giovanile, imp_straniera,  imp_pmi, imp_sedi_ee, imp_eefvg 

### Metadata
Metadata are generated by the pre-rpcessing algorithm and provide information about source and last update. Current version is `r companies$mm_aaaa[1]`. The two attributes (ï..fonte, mm_aaaa) are not relevant for further analysis, and can be removed from the tidy dataset.
```{r}
companies <- companies %>% select( !c(fonte, mm_aaaa))
```

### Identifiers
Each company can be identified by its name, vat number, fiscal code, The following attributes will be used in: 
- denominazione: company name (not a unique identifier, can be spelled in different ways across datasets; moreover different companies may have the same name);
- cf ("codice fiscale"): unique identifier, as factor. Values are unique for each company, but the structure depends on company type: generally a string of 11 digits, but individual companies refer to the owner's code, a string of 16 letters and digits;
- idCompany ("id_impresa"): unique identifier, numeric, created in pre-processing phase.
Other attributes (reg_imp_n,piva, n.albo_art,reg_imp_sez) are not relevant at this stage, and can be dropped. 
All identifiers will be converted to factors.

```{r}
companies <- companies %>% 
             select( !c(reg_imp_n, piva, `n-albo_art`,reg_imp_sez)) %>% 
             rename(name = denominazione) %>%
             rename(idCompany = id_impresa) %>%
             mutate_if(is.character, as.factor) 

```

Now we can ckeck if there are any missing values or duplicates
```{r}
# check missing calues
sum(is.na(companies$name)) + sum(is.na(companies$cf)) == 0
# check duplicates in cf
length(unique(companies$cf)) == length(companies$cf)
# check duplicates in name
uniqueNames <-length(unique(companies$name)) 
allNames<-length(companies$name)
print(paste("Company names are not a valid identifier for further analysis: the dataset contains", uniqueNames, "distinct names out of", allNames, "companies. There are", (allNames-uniqueNames), "duplicates."),quote = FALSE)
```

### active status
Companies that are not active (e.g. due to bankruptcy, liquidation or suspended) are not relevant for the research objectives and can be removed from the dataset. 

```{r}
df<-companies %>% count(stato_impresa) 
ggplot(data=df, aes(x=stato_impresa, y=n)) +   geom_bar(stat="identity") + coord_flip()
companies <- subset(companies, stato_impresa =='ATTIVA')
print(paste("Number of active companies: ", nrow(companies)), quote=FALSE)
```

### head office and local units
Each company has a "registered office" (sede legale) and may have several local units (unità locale). Relevant data is stored in file "t_localizz.csv".
> TODO: add description of variables. Select only companies that are located in Friuli Venezia Giulia, according to prov: province (GO, TS, UD, PN). Select companies that have head office abroad.
sede_ul: "SEDE" or "UL-n" >> factor SEDE = HeadOffice / UL = LocalUnit
Extract the number of local units from attribute "sede_ul"
Create new variable "head-office" true/false 
use "data apertura ul" to improve the estimate of company age (or remove the attribute)
remove unnecessary variables


```{r}
locs <- read_delim( paste0(pathRawData,"/t_localizz.csv")) %>%
             select( c(id_localiz, id_impresa, denominazione,tipo_localizzazione)) %>% 
             rename(name = denominazione) %>%
             rename(idCompany = id_impresa) %>%
             mutate_if(is.character, as.factor) 
```

### Legal form of companies
The legal form of companies can be a relevant attribute for further research. A primary distinction should be made between between 

- *limited liability companies* (società di capitali), mainly  Private Limited Companies by Quotas (società a responsabilità limitata or S.r.l.), Simplified S.r.l. (S.r.l.s.), Public Limited Companies by Shares (società per azioni or S.p.A.). Limited liability companies disclose their financial statements, therefore more relevant information is available.

- *partnerships* (società di persone), mainly Società in nome collettivo (S.n.c.) and Società in accomandita semplice or (S.a.s.)
 
Legal form is encoded in the variable companies$ng, and codes are described in a separate file   */d_ng.csv*. There are over 50 different codes, but the great majority of companies belong to a small number of types. For the purpose of data exploration, the following figure hignliths thee 10 most common legal forms.

```{r}
# company type: keep only the relevan ones for the scope of our research.
types <- read.csv( paste0(pathRawData,"/d_ng.csv"), sep = "|")
companies$ng2           <- as.factor(companies$ng2)
names(types)<-c("ngGroup", "ng2", "ngDescription")

df <- companies  %>% count(ng2) 
df <- df %>% inner_join(types)
df <- df  %>% arrange(-n) %>% head(10)
df$ngDescription <- factor(df$ngDescription, levels = df$ngDescription) 
df 

```
Some company types are not relevant for our research, for example individual companies (DI) and other specified below. Dropping the corresponding dataframe rows drastically reduces the size of the data set
```{r}
notRelevant = c("DI", "AZ", "IR", "ER", "EP", "EN", "EM", "EL", "EE", "SM", "MA", "SZ", "LL", "AM", "AF")
toBeRemoved<-which(companies$ng2 %in% notRelevant)
companies<-companies[-toBeRemoved,]

df <- companies  %>% count(ng2) 
print(paste("The dataset contains ", nrow(df), "types of companies."), quote=FALSE)
df <- df %>% inner_join(types)
df <- df  %>% arrange(-n) 
df$ngDescription <- factor(df$ngDescription, levels = df$ngDescription) #lock factors to keep the same order in the bar plot
ggplot(data=head(df, 10), aes(x=ngDescription, y=n))  + geom_bar(stat="identity") + coord_flip() + ggtitle("Most common types") + geom_text(aes(x=ngDescription, y=n, label = n, hjust = -.2), color = "black") + ylim(NA, 22000)



```

### dates, age of companies, years in business
The dataset provides relevant information in the form of dates. 
```{r}
companies %>% select(starts_with("data")) %>% summary(is.na())
```

The most relevant information for further research is the *age* of the company, that can be assessed as the number of years in business, i.e. the number of years from the earliest date of registration. There are several registration ates (data_iscr_*) and an official start date (data_ini_at), however each attribute has several missing values (NA).


```{r}
#create new atribute "years in business"
companies <- companies %>% 
  rowwise() %>% 
  mutate(dateMin = min(data_isc_ri, data_isc_rd, data_isc_aa, data_ini_at,  na.rm=TRUE)) %>%
  mutate(yearsInBusiness = as.numeric(as.Date("2022-01-01") - dateMin) / 365  )
```

The only attribute to keep for further analysis is *yearsInBusiness*; all *date* columns can be removed from the tidy dataset.
```{r}

#remove all "date" sttributes
companies <- companies %>% select( !starts_with("data"))

```
The distribution of yearsInBusiness is shown below. A 

```{r}
plot1<-ggplot(data=companies, aes(x=yearsInBusiness), show.legend = FALSE) + 
        geom_histogram()
plot2<-ggplot(data=companies, mapping=aes(x=imp_pmi, y=yearsInBusiness))+
        geom_boxplot()  + coord_flip() 

labels = c("years in business", "focus on SMEs")
figure <- ggarrange(plot1, plot2)#,labels = labels, ncol = 1, nrow = 2)
figure
```


Information on bankarupcy should be redundant, since non-active companies have been removed; nevertheless, past check showed unconistend data in the original tables. If bancarupcy dates are present, the company is considered as non-actie and removed. 


 

### employees
addetti_aaaa, addetti_indip, addetti_dip  

### share capital
capitale, capitale_valuta 

### other attributes
> TODO other attributes are relevant as signs of innovation
imp_startup, imp_femminile, imp_giovanile, imp_straniera,  imp_pmi, imp_sedi_ee, imp_eefvg  
show distribution for each

```{r}
companies$imp_pmi       <- as.factor(companies$imp_pmi)
companies$imp_startup   <- as.factor(companies$imp_startup)
companies$imp_giovanile <- as.factor(companies$imp_giovanile)
companies$imp_femminile <- as.factor(companies$imp_femminile)
companies$imp_straniera <- as.factor(companies$imp_straniera)
companies$imp_sedi_ee   <- as.factor(companies$imp_sedi_ee)
```




## NACE activity codes 
Each company is associated with a list of activity codes, according to NACE classification.
The corresponding information is available in *t_codici.csv* . As in previous files, metadata can be inored at this stage.
More info: Complete list of all NACE Code
NACE (Nomenclature of Economic Activities) is the European statistical classification of economic activities. NACE groups organizations according to their business activities.
[https://nacev2.com/en]

```{r}
NACECodes <- read_delim( paste0(pathRawData,"/t_codici.csv"))  %>%
  select(-c(fonte, mm_aaaa))

noCode <- NACECodes %>% filter(is.na(ateco))
percNA <- round(nrow(noCode)/nrow(NACECodes)*100, 2)
compNoCode <- noCode %>% distinct()
percCompNA <- round(nrow(compNoCode)/nrow(companies)*100,2)

```

The dataset contains `r nrow(noCode)` companies, and `r nrow(companies)` NACE codes: each company may have one or more NACE codes, of different types: I (prevealente), P (Primario) and S (Secondario). Unicity is not guaranteed for any type (despite "I" codes are supposed to be unique, in fact many companies have several codes). 

```{r}
# TODO most common sectors (a sector is identified by first two digits of nacecode)
NACECodes["sector"]<-substr(NACECodes$ateco,start=1,stop=2)
df <- NACECodes %>% group_by(sector) %>% summarise( nlocs = n())  %>% arrange(desc(nlocs))   %>% head(10)
p<-ggplot(data=df, aes(x=sector, y=nlocs)) +  geom_bar(stat="identity")
p
```


A company can be **associated with a single NACE code** trough an algorithm, than is to some extent subjective.
 
Some companies have **no NACE codes associated**: this is an issue with the original data affecting a small portion of the dataset (in this example `r nrow(noCode)` missing values out of `r nrow(NACECodes)`, or `r percNA`%). Since each company may have more codes, the number of companies without *any NACE code* is smaller: only `r length(compNoCode)` out of `r nrow(companies)` i.e. `r percCompNA`%.  Rows with NAs are removed from the dataset. 

Moreover, NACE codes are **associated with company localization**. In order to reduce the compexity, we may summarize NACE codes by company, but this can lead to misinterpretation in some cases. Consider, for example, a company has its head office in Rome, with several codes in sector 47, and a local unit in Trieste engaged in different activities with a single code in sector 22. If we summarise codes by company our case study belongs to sector 47; instead, if we summarize by localization, the company belongs to sector 22. 

For the purpose of data elxploration and preliminary feature selection, we filer companies and locs to retain only rows that are associated with NACE codes. 

```{r}
loc_in_NACE <- NACECodes %>% select(id_localiz) %>% distinct()   #unique id_localiz associated with NACE
locs <- locs %>% filter(id_localiz %in% loc_in_NACE$id_localiz)  #filter locs dataframe
companies <- companies %>% filter(idCompany %in% locs$idCompany) #filter companies dataframe
```
 
> TODO sectors are identified by first two digits of NACE codes.

<!-- ``` -->
<!-- Not all sectors are relevant for the research topic. We can restrict the dataset to manufacturing activities (codes 10 to 33)and research (sector = 72) -->

<!--  ```{r} -->

<!-- relevantSectors <- seq(10,33)  -->
<!-- relevantSectors <- c(relevantSectors,72)  -->
<!-- relevantSectors -->

<!-- NACECodes <- NACECodes %>% filter(sector %in% relevantSectors)      #filtering codes -->
<!-- companies <- companies %>% filter(id_impresa %in% NACECodes$id_impresa) #filtering companies -->

<!-- print(paste("Number of companies reduced to ", nrow(companies))) -->

<!-- ``` -->

 
 
 



<!--  ```{r} -->
<!-- companies2 <-subset(companies,capitale_valuta == "EURO") -->
<!-- companies2 <-subset(companies2,capitale < 1e6) -->
<!-- companies2 <-subset(companies2,ng2 == "SP") -->


<!-- boxplot(companies2$capitale) -->
<!-- qplot(companies2$capitale, geom="histogram") -->
<!-- ``` -->


<!--  ```{r} -->


companies<- subset(companies2, select = c('eta', 'cf', 'id_impresa') )
ids <- unique(companies2$id_impresa)
localiz <- read.csv("t_localizz.csv", sep = "|")
localiz <- localiz[localiz$id_impresa %in% ids,]
localiz <- subset(localiz, select = c('id_impresa', 'id_localiz'))
locs <- unique(localiz$id_localiz)
codici <- read.csv("t_codici.csv", sep = "|")
codici <- codici[codici$id_localiz %in% locs,]
codici <- subset(codici, select = c('id_localiz', 'ateco'))

codici = merge(codici, localiz, by = "id_localiz")

imp <- data.frame("company"=ids)
imp$eta <- companies$eta
imp$ateco <- NA

<!-- #aggiunge al data.frame una lista di codici ateco -->
<!-- for (impresa in imp$company){ -->
<!--         temp = as.list(subset(codici, id_impresa == impresa)) -->
<!--         unique_NACE_codes <- unique(temp$ateco) -->
<!--         rownum = which(imp$company == impresa) -->
<!--         imp$ateco[rownum] <- list(unique_NACE_codes) -->
<!-- } -->

"
'''"

## tidy dataset

Now we can save the filtered and cleaned data to a csv. The number of features is reduced to...
The dataset is composed of .. .main files (t_cmp.csv, t_nace.csv) and ... files with extended descriptions (d_ng, d_nace).
```{r}

companies %>% write_csv(paste0(pathTidyData,"t_cmp.csv"),)

```

<!--chapter:end:01-imprese.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# Exploring dataset "bilanciFVG"
This section is dedicated to load and preprocess financial statement data for the dataset *imprese-fvg*. 
The relevant file is "_DATA/imprese-fvg/bilanci-fvg.csv".

```{r include=FALSE}
# Local path, no need to display in knitted version
pathRawData = './../../_data/raw/'
pathTidyData = './../../_data/tidy/'
library("tidyverse")
```
 
The relevant file is *bilanci-fvg.csv*. Each observation is a summary of balance sheet data (bsd) of a company (identified by *cf*) for a given year. Column labels need some improvement to remove whitespaces and possibly short english names.
 

```{r}
bsd <- read_delim( paste0(pathRawData,"imprese/bilanci-fvg.csv") ) 
spec(bsd) # tydiverse for str(companies)

```

```{r}
bsd <- bsd %>% 
        rename(year = anno) %>%
        rename(totEquity = `Totale patrimonio netto`) %>%
        rename(totAssets = `Totale attivo`) %>%
        rename(totIntang = `Totale Immobilizzazioni immateriali`) %>%
        rename(staffCost = `Totale Costi del Personale`) %>%
        rename(turnover  = `Ricavi delle vendite`) %>%
        select(cf,year,turnover, totAssets, totIntang, staffCost  )  

```


```{r}
bsd <- bsd %>% 
  mutate(across(everything(), gsub, pattern = "[.]", replacement = "")) %>%
  mutate(across(everything(), gsub, pattern = ",", replacement = ".")) %>%
  mutate(across(.cols = 2:6, .fns = as.numeric))

```



```{r}
bsd %>% write_csv(paste0(pathTidyData,"bsd.csv"))
```



There are 18 columns but in this project we will use only 4, namely "cf", "year", revenues" and "staff cost". Data should be loaded as string and then converted taking into account some issues with format of numerical variables. 
 
To convert bsd$revenues and bsd$staffcost to numbers, we need to remove the "." used as thousand separators, and replace "," with "." as a decimal separator.

We will focus the analysis on a list of companies that are tenats at Area Science Park. The list is available in the file "data/imprese-fvg/area-tenants.csv" so we can load it in al list ("filter") and use it to subset *bsd*.

```{r}

tenants <- read_delim( paste0(pathRawData,"area-science-park/tenants.txt") ) %>%
  select(cf)  

tens = c(tenants$cf)
bsd_tenants <- bsd %>% subset(cf %in% tenants$cf) %>% 
                mutate(cf = as.factor(cf)) %>% drop_na() 
  
```
The variable bsd$revenues spans from 0 to 1e9, so it is more convenient to work with log10

```{r}
library(ggplot2)
library(ggpubr)
bsd3 <- bsd %>% subset(turnover > 1000) %>% subset(year = 2019)
bsd3$logturnover <- log10(bsd3$turnover)
# hist(bsd$turnover)
# hist(bsd$logturnover)
h1 <- ggplot(bsd3, aes(x=turnover)) + geom_histogram(color="black", fill="red")
h2 <- ggplot(bsd3, aes(x=logturnover)) + geom_histogram(color="black", fill="green", aes(y=..density..))+  geom_density(alpha=.2, fill="#FF6666") 
figure <- ggarrange(h1, h2,labels = c("linear", "log"), ncol = 2, nrow = 1)
figure

```
 
 
 
```{r}
bsd_tenants$logturnover <- log10(bsd_tenants$turnover)

tmp <- bsd_tenants  %>%
              subset(year >= 2016) %>% 
              mutate(year = as.factor(year))

figure <- ggplot(tmp, aes(x=logturnover,fill=year)) + geom_density(alpha=.2)  
figure

```



<!--chapter:end:02-bilanci.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# Exploring dataset CO-FVG


```{r include=FALSE}
# Local path, no need to display in knitted version

pathRawData = 'C:/Users/morea/OneDrive - Area Science Park/General - iifvg lavoro/DatiElaborati/Riservati/'
pathTidyData = './../../_data/tidy/'
library("tidyverse")
data.files <- list.files(pathRawData, pattern = "dati_*", recursive = TRUE )
```


The original data is organized in `r length(data.files)` files: `r data.files`. 
> TODO Currently, data exploration phase is focused on only one of the files above. Should extend it to all files using a for loop and appending results to a data.frame.

```{r}
empl <- read_delim( paste0(pathRawData,"dati_2018.csv")) 

features <-names(empl)
some_features <- c("CF","anno","eta","genere","iso3","professione","qualifica","saldo")


```

 There are `r length(features)` features available: `r features`. For the purpose of data exploration we will focus only on the following: `r some_features`.


```{r}

empl <- empl %>%  
  select( one_of(some_features) ) %>%
  rename( year = anno)
 
empl_flows <- empl %>% select( c(CF, saldo, year)) %>%  
  mutate(hf = factor(saldo))%>% 
  mutate(hf=recode(hf,`-1`="fired",`1`="hired"))%>%
  group_by(CF,hf, year) %>% 
  summarize(hiredfired=  sum(saldo) ) %>% 
  pivot_wider( names_from = hf, values_from = hiredfired) %>%
  replace(is.na(.), 0) %>%
  mutate(turnover = hired-fired) %>%
  mutate(net = hired+fired) 
 
```


```{r}
employees_hired = log10(empl_flows$hired)
employees_fired=  log10(-empl_flows$fired)
ggplot(empl_flows, aes(x=employees_hired, y=employees_fired))+
    geom_point()



```



```{r}
employees_hired = (empl_flows$hired)
employees_fired=  (-empl_flows$fired)
ggplot(empl_flows, aes(x=employees_hired, y=employees_fired))+
    geom_point()



```
 > TODO import, calculate net saldo and turnover, divide companies in quartiles

> TODO improve formatting tables with library(kableExtra) %>% kable()


```{r}
empl_flows %>% write_csv(paste0(pathTidyData,"empl_flows.csv"),)
```


<!--chapter:end:03-CO.Rmd-->

